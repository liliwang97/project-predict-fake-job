{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0Q67tVVUUDHf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "y5bFzu22Ueui",
    "outputId": "206c4153-1795-4302-a2e6-b9cb823c66fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
       "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/fake_job_postings.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KZwT55XUgaY",
    "outputId": "e9c9107a-1fe9-49df-cf3c-ecb5fce92cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17880 entries, 0 to 17879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17880 non-null  int64 \n",
      " 1   title                17880 non-null  object\n",
      " 2   location             17534 non-null  object\n",
      " 3   department           6333 non-null   object\n",
      " 4   salary_range         2868 non-null   object\n",
      " 5   company_profile      14572 non-null  object\n",
      " 6   description          17879 non-null  object\n",
      " 7   requirements         15185 non-null  object\n",
      " 8   benefits             10670 non-null  object\n",
      " 9   telecommuting        17880 non-null  int64 \n",
      " 10  has_company_logo     17880 non-null  int64 \n",
      " 11  has_questions        17880 non-null  int64 \n",
      " 12  employment_type      14409 non-null  object\n",
      " 13  required_experience  10830 non-null  object\n",
      " 14  required_education   9775 non-null   object\n",
      " 15  industry             12977 non-null  object\n",
      " 16  function             11425 non-null  object\n",
      " 17  fraudulent           17880 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data[[\"title\", \"location\", \"company_profile\", \"description\", \"requirements\", \n",
    "               \"benefits\", \"telecommuting\",\"has_company_logo\",\"has_questions\",\"employment_type\",\n",
    "               \"required_experience\",\"industry\",\"function\",\"fraudulent\"]]\n",
    "#new_df = new_df.dropna()\n",
    "#new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WvAJcxbWNTz",
    "outputId": "de01bb51-94cf-49ea-b9f0-0042b19567ca"
   },
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Q4gqYAvH36",
    "outputId": "c963f095-2b1e-453d-aaf1-2c6c75d3195e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lilyw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/lilyw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lilyw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/lilyw/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# text preprocessing function\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1ZRPW2Htv6pO",
    "outputId": "0367225d-5293-4681-b5da-d607e62d2e41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['title'].fillna('unknown', inplace=True)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['company_profile'].fillna('unknown', inplace=True)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['description'].fillna('unknown', inplace=True)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['requirements'].fillna('unknown', inplace=True)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['benefits'].fillna('unknown', inplace=True)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['preprocessed_title'] = text_df['title'].apply(preprocess_text)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['preprocessed_company_profile'] = text_df['company_profile'].apply(preprocess_text)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['preprocessed_description'] = text_df['description'].apply(preprocess_text)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['preprocessed_requirements'] = text_df['requirements'].apply(preprocess_text)\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/523841265.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['preprocessed_benefits'] = text_df['benefits'].apply(preprocess_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>preprocessed_company_profile</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>preprocessed_requirements</th>\n",
       "      <th>preprocessed_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>marketing intern</td>\n",
       "      <td>'re food52 've created groundbreaking award-wi...</td>\n",
       "      <td>food52 fast-growing james beard award-winning ...</td>\n",
       "      <td>experience content management system major plu...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>customer service cloud video production</td>\n",
       "      <td>90 second world cloud video production service...</td>\n",
       "      <td>organised focused vibrant awesome passion cust...</td>\n",
       "      <td>expect key responsibility communicate client 9...</td>\n",
       "      <td>get usthrough part 90 second team gain experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>commissioning machinery assistant cma</td>\n",
       "      <td>valor service provides workforce solution meet...</td>\n",
       "      <td>client located houston actively seeking experi...</td>\n",
       "      <td>implement pre-commissioning commissioning proc...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>account executive washington dc</td>\n",
       "      <td>passion improving quality life geography heart...</td>\n",
       "      <td>company esri – environmental system research i...</td>\n",
       "      <td>education bachelor ’ master ’ gi business admi...</td>\n",
       "      <td>culture anything corporate—we collaborative cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>bill review manager</td>\n",
       "      <td>spotsource solution llc global human capital m...</td>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "      <td>qualification rn license state texasdiploma ba...</td>\n",
       "      <td>full benefit offered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0                           Marketing Intern   \n",
       "1  Customer Service - Cloud Video Production   \n",
       "2    Commissioning Machinery Assistant (CMA)   \n",
       "3          Account Executive - Washington DC   \n",
       "4                        Bill Review Manager   \n",
       "\n",
       "                                     company_profile  \\\n",
       "0  We're Food52, and we've created a groundbreaki...   \n",
       "1  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2  Valor Services provides Workforce Solutions th...   \n",
       "3  Our passion for improving quality of life thro...   \n",
       "4  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  \\\n",
       "0                                            unknown   \n",
       "1  What you will get from usThrough being part of...   \n",
       "2                                            unknown   \n",
       "3  Our culture is anything but corporate—we have ...   \n",
       "4                              Full Benefits Offered   \n",
       "\n",
       "                        preprocessed_title  \\\n",
       "0                         marketing intern   \n",
       "1  customer service cloud video production   \n",
       "2    commissioning machinery assistant cma   \n",
       "3          account executive washington dc   \n",
       "4                      bill review manager   \n",
       "\n",
       "                        preprocessed_company_profile  \\\n",
       "0  're food52 've created groundbreaking award-wi...   \n",
       "1  90 second world cloud video production service...   \n",
       "2  valor service provides workforce solution meet...   \n",
       "3  passion improving quality life geography heart...   \n",
       "4  spotsource solution llc global human capital m...   \n",
       "\n",
       "                            preprocessed_description  \\\n",
       "0  food52 fast-growing james beard award-winning ...   \n",
       "1  organised focused vibrant awesome passion cust...   \n",
       "2  client located houston actively seeking experi...   \n",
       "3  company esri – environmental system research i...   \n",
       "4  job title itemization review managerlocation f...   \n",
       "\n",
       "                           preprocessed_requirements  \\\n",
       "0  experience content management system major plu...   \n",
       "1  expect key responsibility communicate client 9...   \n",
       "2  implement pre-commissioning commissioning proc...   \n",
       "3  education bachelor ’ master ’ gi business admi...   \n",
       "4  qualification rn license state texasdiploma ba...   \n",
       "\n",
       "                               preprocessed_benefits  \n",
       "0                                            unknown  \n",
       "1  get usthrough part 90 second team gain experie...  \n",
       "2                                            unknown  \n",
       "3  culture anything corporate—we collaborative cr...  \n",
       "4                               full benefit offered  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace NA\n",
    "text_df = new_df[[\"title\", \"company_profile\", \"description\", \"requirements\", \"benefits\"]]\n",
    "text_df['title'].fillna('unknown', inplace=True)\n",
    "text_df['company_profile'].fillna('unknown', inplace=True)\n",
    "text_df['description'].fillna('unknown', inplace=True)\n",
    "text_df['requirements'].fillna('unknown', inplace=True)\n",
    "text_df['benefits'].fillna('unknown', inplace=True)\n",
    "\n",
    "# process text columns\n",
    "text_df['preprocessed_title'] = text_df['title'].apply(preprocess_text)\n",
    "text_df['preprocessed_company_profile'] = text_df['company_profile'].apply(preprocess_text)\n",
    "text_df['preprocessed_description'] = text_df['description'].apply(preprocess_text)\n",
    "text_df['preprocessed_requirements'] = text_df['requirements'].apply(preprocess_text)\n",
    "text_df['preprocessed_benefits'] = text_df['benefits'].apply(preprocess_text)\n",
    "\n",
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17880, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "megnV4TF9Aiy"
   },
   "source": [
    "# 2. Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Vectorization method 1: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud1mJwRI78Ay",
    "outputId": "002f6649-1a7b-4af4-8dd7-fbc664014f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessed_title':         16   18  abroad   account  admin  administrative  administrator  \\\n",
      "0      0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "1      0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "2      0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "3      0.0  0.0     0.0  0.700986    0.0             0.0            0.0   \n",
      "4      0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "...    ...  ...     ...       ...    ...             ...            ...   \n",
      "17875  0.0  0.0     0.0  0.698317    0.0             0.0            0.0   \n",
      "17876  0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "17877  0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "17878  0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "17879  0.0  0.0     0.0  0.000000    0.0             0.0            0.0   \n",
      "\n",
      "       agent  analyst  android  ...  system  teacher  team  technical  \\\n",
      "0        0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "1        0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "2        0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "3        0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "4        0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "...      ...      ...      ...  ...     ...      ...   ...        ...   \n",
      "17875    0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "17876    0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "17877    0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "17878    0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "17879    0.0      0.0      0.0  ...     0.0      0.0   0.0        0.0   \n",
      "\n",
      "       technician  time   ui   ux       web  year  \n",
      "0             0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "1             0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "2             0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "3             0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "4             0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "...           ...   ...  ...  ...       ...   ...  \n",
      "17875         0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "17876         0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "17877         0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "17878         0.0   0.0  0.0  0.0  0.000000   0.0  \n",
      "17879         0.0   0.0  0.0  0.0  0.567829   0.0  \n",
      "\n",
      "[17880 rows x 100 columns], 'preprocessed_company_profile':          across    agency      also       amp  application    around  based  \\\n",
      "0      0.000000  0.000000  0.150591  0.000000          0.0  0.159385    0.0   \n",
      "1      0.000000  0.159341  0.000000  0.000000          0.0  0.000000    0.0   \n",
      "2      0.178532  0.000000  0.000000  0.147298          0.0  0.000000    0.0   \n",
      "3      0.000000  0.000000  0.000000  0.000000          0.0  0.226310    0.0   \n",
      "4      0.132305  0.000000  0.000000  0.000000          0.0  0.000000    0.0   \n",
      "...         ...       ...       ...       ...          ...       ...    ...   \n",
      "17875  0.000000  0.000000  0.080439  0.000000          0.0  0.000000    0.0   \n",
      "17876  0.000000  0.000000  0.000000  0.087852          0.0  0.000000    0.0   \n",
      "17877  0.000000  0.000000  0.000000  0.000000          0.0  0.000000    0.0   \n",
      "17878  0.000000  0.000000  0.000000  0.000000          0.0  0.000000    0.0   \n",
      "17879  0.000000  0.000000  0.080439  0.000000          0.0  0.000000    0.0   \n",
      "\n",
      "           best     brand  build  ...     value      want       way        we  \\\n",
      "0      0.147137  0.000000    0.0  ...  0.000000  0.000000  0.151483  0.273215   \n",
      "1      0.000000  0.302929    0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2      0.000000  0.000000    0.0  ...  0.174446  0.000000  0.159615  0.143940   \n",
      "3      0.000000  0.000000    0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "4      0.229784  0.000000    0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "...         ...       ...    ...  ...       ...       ...       ...       ...   \n",
      "17875  0.000000  0.083149    0.0  ...  0.000000  0.438063  0.080916  0.000000   \n",
      "17876  0.000000  0.195651    0.0  ...  0.000000  0.103077  0.000000  0.085849   \n",
      "17877  0.000000  0.000000    0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "17878  0.000000  0.000000    0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "17879  0.000000  0.083149    0.0  ...  0.000000  0.438063  0.080916  0.000000   \n",
      "\n",
      "       web      well      work   working     world  year  \n",
      "0      0.0  0.158937  0.000000  0.000000  0.000000   0.0  \n",
      "1      0.0  0.000000  0.000000  0.142847  0.496347   0.0  \n",
      "2      0.0  0.000000  0.000000  0.000000  0.000000   0.0  \n",
      "3      0.0  0.000000  0.000000  0.000000  0.362152   0.0  \n",
      "4      0.0  0.000000  0.000000  0.000000  0.000000   0.0  \n",
      "...    ...       ...       ...       ...       ...   ...  \n",
      "17875  0.0  0.000000  0.181167  0.313674  0.000000   0.0  \n",
      "17876  0.0  0.000000  0.000000  0.000000  0.000000   0.0  \n",
      "17877  0.0  0.000000  0.000000  0.000000  0.000000   0.0  \n",
      "17878  0.0  0.000000  0.000000  0.000000  0.000000   0.0  \n",
      "17879  0.0  0.000000  0.181167  0.313674  0.000000   0.0  \n",
      "\n",
      "[17880 rows x 100 columns], 'preprocessed_description':        ability   account      also       amp  application  apply     based  \\\n",
      "0          0.0  0.000000  0.000000  0.196544     0.000000    0.0  0.000000   \n",
      "1          0.0  0.119385  0.000000  0.090225     0.000000    0.0  0.087252   \n",
      "2          0.0  0.000000  0.000000  0.000000     0.000000    0.0  0.000000   \n",
      "3          0.0  0.701003  0.000000  0.000000     0.000000    0.0  0.000000   \n",
      "4          0.0  0.000000  0.000000  0.000000     0.000000    0.0  0.000000   \n",
      "...        ...       ...       ...       ...          ...    ...       ...   \n",
      "17875      0.0  0.000000  0.000000  0.129033     0.000000    0.0  0.124781   \n",
      "17876      0.0  0.456097  0.196436  0.000000     0.194089    0.0  0.000000   \n",
      "17877      0.0  0.000000  0.000000  0.000000     0.000000    0.0  0.000000   \n",
      "17878      0.0  0.000000  0.000000  0.000000     0.000000    0.0  0.000000   \n",
      "17879      0.0  0.000000  0.142388  0.000000     0.000000    0.0  0.120811   \n",
      "\n",
      "           best     build  business  ...  user   we       web   website  \\\n",
      "0      0.000000  0.000000  0.000000  ...   0.0  0.0  0.000000  0.262554   \n",
      "1      0.000000  0.000000  0.224229  ...   0.0  0.0  0.000000  0.000000   \n",
      "2      0.000000  0.000000  0.000000  ...   0.0  0.0  0.000000  0.000000   \n",
      "3      0.000000  0.060873  0.263324  ...   0.0  0.0  0.000000  0.000000   \n",
      "4      0.000000  0.000000  0.000000  ...   0.0  0.0  0.000000  0.000000   \n",
      "...         ...       ...       ...  ...   ...  ...       ...       ...   \n",
      "17875  0.000000  0.148260  0.106891  ...   0.0  0.0  0.151310  0.172370   \n",
      "17876  0.000000  0.000000  0.000000  ...   0.0  0.0  0.202103  0.000000   \n",
      "17877  0.000000  0.000000  0.000000  ...   0.0  0.0  0.000000  0.000000   \n",
      "17878  0.000000  0.000000  0.000000  ...   0.0  0.0  0.000000  0.000000   \n",
      "17879  0.139963  0.000000  0.103490  ...   0.0  0.0  0.146496  0.000000   \n",
      "\n",
      "           well    within      work   working     world      year  \n",
      "0      0.000000  0.000000  0.263408  0.000000  0.000000  0.000000  \n",
      "1      0.000000  0.000000  0.060460  0.085262  0.536096  0.000000  \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3      0.000000  0.119686  0.035501  0.000000  0.125913  0.000000  \n",
      "4      0.160521  0.000000  0.102909  0.000000  0.000000  0.000000  \n",
      "...         ...       ...       ...       ...       ...       ...  \n",
      "17875  0.000000  0.000000  0.000000  0.121935  0.306672  0.000000  \n",
      "17876  0.180147  0.194680  0.230981  0.000000  0.000000  0.000000  \n",
      "17877  0.000000  0.000000  0.076466  0.000000  0.000000  0.000000  \n",
      "17878  0.000000  0.000000  0.000000  0.247990  0.000000  0.000000  \n",
      "17879  0.130581  0.141116  0.502285  0.000000  0.445372  0.132892  \n",
      "\n",
      "[17880 rows x 100 columns], 'preprocessed_requirements':         ability      able       amp       and  application  attention  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000     0.000000   0.290380   \n",
      "1      0.092639  0.118939  0.128920  0.131768     0.000000   0.146475   \n",
      "2      0.000000  0.000000  0.000000  0.000000     0.000000   0.000000   \n",
      "3      0.112822  0.000000  0.000000  0.160475     0.000000   0.000000   \n",
      "4      0.000000  0.213064  0.230944  0.000000     0.000000   0.000000   \n",
      "...         ...       ...       ...       ...          ...        ...   \n",
      "17875  0.095987  0.000000  0.400737  0.000000     0.000000   0.000000   \n",
      "17876  0.233732  0.000000  0.000000  0.000000     0.000000   0.184781   \n",
      "17877  0.104344  0.000000  0.000000  0.000000     0.000000   0.164982   \n",
      "17878  0.000000  0.419892  0.455128  0.000000     0.000000   0.000000   \n",
      "17879  0.000000  0.000000  0.000000  0.000000     0.447402   0.000000   \n",
      "\n",
      "       bachelor  background  business  candidate  ...  user     using  \\\n",
      "0      0.000000         0.0  0.000000    0.00000  ...   0.0  0.000000   \n",
      "1      0.000000         0.0  0.000000    0.00000  ...   0.0  0.140732   \n",
      "2      0.000000         0.0  0.000000    0.00000  ...   0.0  0.000000   \n",
      "3      0.175795         0.0  0.142824    0.00000  ...   0.0  0.000000   \n",
      "4      0.258580         0.0  0.000000    0.00000  ...   0.0  0.000000   \n",
      "...         ...         ...       ...        ...  ...   ...       ...   \n",
      "17875  0.000000         0.0  0.243025    0.00000  ...   0.0  0.000000   \n",
      "17876  0.000000         0.0  0.000000    0.00000  ...   0.0  0.000000   \n",
      "17877  0.000000         0.0  0.132092    0.00000  ...   0.0  0.000000   \n",
      "17878  0.000000         0.0  0.000000    0.00000  ...   0.0  0.000000   \n",
      "17879  0.000000         0.0  0.000000    0.22865  ...   0.0  0.229030   \n",
      "\n",
      "        verbal  web      well    within      work   working   written  \\\n",
      "0      0.00000  0.0  0.000000  0.000000  0.000000  0.422144  0.000000   \n",
      "1      0.00000  0.0  0.000000  0.000000  0.167326  0.106470  0.000000   \n",
      "2      0.00000  0.0  0.000000  0.000000  0.263217  0.000000  0.000000   \n",
      "3      0.15001  0.0  0.000000  0.000000  0.101890  0.000000  0.130011   \n",
      "4      0.00000  0.0  0.000000  0.000000  0.149872  0.190729  0.000000   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "17875  0.00000  0.0  0.000000  0.148689  0.173373  0.110318  0.000000   \n",
      "17876  0.00000  0.0  0.169946  0.000000  0.316627  0.000000  0.000000   \n",
      "17877  0.00000  0.0  0.000000  0.000000  0.094234  0.119923  0.000000   \n",
      "17878  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "17879  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "           year  \n",
      "0      0.000000  \n",
      "1      0.000000  \n",
      "2      0.000000  \n",
      "3      0.191482  \n",
      "4      0.140827  \n",
      "...         ...  \n",
      "17875  0.000000  \n",
      "17876  0.198345  \n",
      "17877  0.177093  \n",
      "17878  0.000000  \n",
      "17879  0.127938  \n",
      "\n",
      "[17880 rows x 100 columns], 'preprocessed_benefits':        401k      also       amp  application     apply     based   benefit  \\\n",
      "0       0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.000000   \n",
      "1       0.0  0.164450  0.000000          0.0  0.365533  0.152966  0.000000   \n",
      "2       0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.000000   \n",
      "3       0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.000000   \n",
      "4       0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.625539   \n",
      "...     ...       ...       ...          ...       ...       ...       ...   \n",
      "17875   0.0  0.120783  0.000000          0.0  0.134236  0.000000  0.000000   \n",
      "17876   0.0  0.000000  0.408658          0.0  0.000000  0.000000  0.000000   \n",
      "17877   0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.000000   \n",
      "17878   0.0  0.000000  0.000000          0.0  0.000000  0.337939  0.000000   \n",
      "17879   0.0  0.000000  0.000000          0.0  0.000000  0.000000  0.000000   \n",
      "\n",
      "           best  bonus  business  ...  vacation  vision      want        we  \\\n",
      "0      0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "1      0.000000    0.0   0.17101  ...  0.000000     0.0  0.000000  0.000000   \n",
      "2      0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "3      0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.359712   \n",
      "4      0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "...         ...    ...       ...  ...       ...     ...       ...       ...   \n",
      "17875  0.122609    0.0   0.00000  ...  0.000000     0.0  0.129169  0.387652   \n",
      "17876  0.000000    0.0   0.00000  ...  0.205635     0.0  0.000000  0.000000   \n",
      "17877  0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "17878  0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "17879  0.000000    0.0   0.00000  ...  0.000000     0.0  0.000000  0.000000   \n",
      "\n",
      "           week  well      work  working     world  year  \n",
      "0      0.000000   0.0  0.000000  0.00000  0.000000   0.0  \n",
      "1      0.000000   0.0  0.000000  0.42092  0.171126   0.0  \n",
      "2      0.000000   0.0  0.000000  0.00000  0.000000   0.0  \n",
      "3      0.000000   0.0  0.233889  0.00000  0.000000   0.0  \n",
      "4      0.000000   0.0  0.000000  0.00000  0.000000   0.0  \n",
      "...         ...   ...       ...      ...       ...   ...  \n",
      "17875  0.000000   0.0  0.588130  0.10305  0.125686   0.0  \n",
      "17876  0.252648   0.0  0.160827  0.00000  0.000000   0.0  \n",
      "17877  0.000000   0.0  0.000000  0.00000  0.000000   0.0  \n",
      "17878  0.000000   0.0  0.252725  0.00000  0.000000   0.0  \n",
      "17879  0.000000   0.0  0.000000  0.00000  0.000000   0.0  \n",
      "\n",
      "[17880 rows x 100 columns]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "columns_to_vectorize = [\"preprocessed_title\", \"preprocessed_company_profile\", \"preprocessed_description\", \"preprocessed_requirements\", \"preprocessed_benefits\"]\n",
    "\n",
    "tfidf_data = {}\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "for column in columns_to_vectorize:\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(text_df[column])\n",
    "    tfidf_data[column] = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17880, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframe\n",
    "vect_df = pd.concat([tfidf_data[\"preprocessed_title\"], tfidf_data[\"preprocessed_company_profile\"]], axis=1)\n",
    "vect_df = pd.concat([vect_df, tfidf_data[\"preprocessed_description\"]], axis=1)\n",
    "vect_df = pd.concat([vect_df, tfidf_data[\"preprocessed_requirements\"]], axis=1)\n",
    "vect_df = pd.concat([vect_df, tfidf_data[\"preprocessed_benefits\"]], axis=1)\n",
    "#vect_df = pd.concat([vect_df, new_df[\"fraudulent\"]], axis=1)\n",
    "\n",
    "y = new_df[\"fraudulent\"]\n",
    "vect_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Vectorization method 2: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    return tokens\n",
    "\n",
    "bert_token_data = pd.DataFrame()\n",
    "bert_token_data['tokenized_title'] = text_df[\"preprocessed_title\"].apply(tokenize_and_encode)\n",
    "bert_token_data['tokenized_company_profile'] = text_df[\"preprocessed_company_profile\"].apply(tokenize_and_encode)\n",
    "bert_token_data['tokenized_description'] = text_df[\"preprocessed_description\"].apply(tokenize_and_encode)\n",
    "bert_token_data['tokenized_requirements'] = text_df[\"preprocessed_requirements\"].apply(tokenize_and_encode)\n",
    "bert_token_data['tokenized_benefits'] = text_df[\"preprocessed_benefits\"].apply(tokenize_and_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 1: 515.072433 seconds\n",
      "Elapsed time 2: 2211.640417 seconds\n",
      "Elapsed time 3: 5175.414101 seconds\n",
      "Elapsed time 4: 6943.254818 seconds\n",
      "Elapsed time5: 7883.984557 seconds\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "def extract_word_embeddings(tokens):\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state\n",
    "\n",
    "bert_data = pd.DataFrame()\n",
    "bert_data['word_embedding_title'] = bert_token_data['tokenized_title'].apply(extract_word_embeddings)\n",
    "elapsed_time = datetime.now() - start_time\n",
    "print(\"Elapsed time 1:\", elapsed_time.total_seconds(), \"seconds\")\n",
    "\n",
    "bert_data['word_embedding_company_profile'] = bert_token_data['tokenized_company_profile'].apply(extract_word_embeddings)\n",
    "elapsed_time = datetime.now() - start_time\n",
    "print(\"Elapsed time 2:\", elapsed_time.total_seconds(), \"seconds\")\n",
    "\n",
    "bert_data['word_embedding_description'] = bert_token_data['tokenized_description'].apply(extract_word_embeddings)\n",
    "elapsed_time = datetime.now() - start_time\n",
    "print(\"Elapsed time 3:\", elapsed_time.total_seconds(), \"seconds\")\n",
    "\n",
    "bert_data['word_embedding_requirements'] = bert_token_data['tokenized_requirements'].apply(extract_word_embeddings)\n",
    "elapsed_time = datetime.now() - start_time\n",
    "print(\"Elapsed time 4:\", elapsed_time.total_seconds(), \"seconds\")\n",
    "\n",
    "bert_data['word_embedding_benefits'] = bert_token_data['tokenized_benefits'].apply(extract_word_embeddings)\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time5:\", elapsed_time.total_seconds(), \"seconds\")\n",
    "\n",
    "bert_data.to_pickle('tensor_bert_data.pkl')\n",
    "bert_data.to_csv(\"bert_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word_embedding_title</th>\n",
       "      <th>word_embedding_company_profile</th>\n",
       "      <th>word_embedding_description</th>\n",
       "      <th>word_embedding_requirements</th>\n",
       "      <th>word_embedding_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tensor([[[-0.2762,  0.2952, -0.2674,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.1387,  0.0414,  0.3453,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.1852,  0.1841,  0.0177,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2802,  0.0395,  0.0526,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.4404,  0.1208, -0.3744,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tensor([[[-0.4242,  0.0289, -0.2216,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.3376,  0.1549,  0.2261,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.0900,  0.1768,  0.6600,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2514, -0.0361,  0.2124,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2629,  0.1672,  0.4715,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tensor([[[-0.4066,  0.3469, -0.2398,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.5047, -0.0219,  0.1005,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2912,  0.2402,  0.4106,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2419, -0.0465,  0.6407,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.4404,  0.1208, -0.3744,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tensor([[[-0.3563,  0.0420, -0.1740,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.4097, -0.3133,  0.1103,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.3401,  0.0642,  0.0743,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.2363,  0.1603,  0.1603,  ..., -0....</td>\n",
       "      <td>tensor([[[ 0.0051, -0.1624, -0.1307,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tensor([[[-0.3451,  0.2884,  0.0088,  ..., -0....</td>\n",
       "      <td>tensor([[[-1.8440e-01,  1.9524e-01,  1.8527e-0...</td>\n",
       "      <td>tensor([[[-0.3737,  0.4446,  0.3489,  ..., -0....</td>\n",
       "      <td>tensor([[[-0.4553,  0.0736,  0.1529,  ..., -0....</td>\n",
       "      <td>tensor([[[-2.5761e-01,  3.7348e-02, -3.8978e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               word_embedding_title  \\\n",
       "0           0  tensor([[[-0.2762,  0.2952, -0.2674,  ..., -0....   \n",
       "1           1  tensor([[[-0.4242,  0.0289, -0.2216,  ..., -0....   \n",
       "2           2  tensor([[[-0.4066,  0.3469, -0.2398,  ..., -0....   \n",
       "3           3  tensor([[[-0.3563,  0.0420, -0.1740,  ..., -0....   \n",
       "4           4  tensor([[[-0.3451,  0.2884,  0.0088,  ..., -0....   \n",
       "\n",
       "                      word_embedding_company_profile  \\\n",
       "0  tensor([[[-0.1387,  0.0414,  0.3453,  ..., -0....   \n",
       "1  tensor([[[-0.3376,  0.1549,  0.2261,  ..., -0....   \n",
       "2  tensor([[[-0.5047, -0.0219,  0.1005,  ..., -0....   \n",
       "3  tensor([[[-0.4097, -0.3133,  0.1103,  ..., -0....   \n",
       "4  tensor([[[-1.8440e-01,  1.9524e-01,  1.8527e-0...   \n",
       "\n",
       "                          word_embedding_description  \\\n",
       "0  tensor([[[-0.1852,  0.1841,  0.0177,  ..., -0....   \n",
       "1  tensor([[[-0.0900,  0.1768,  0.6600,  ..., -0....   \n",
       "2  tensor([[[-0.2912,  0.2402,  0.4106,  ..., -0....   \n",
       "3  tensor([[[-0.3401,  0.0642,  0.0743,  ..., -0....   \n",
       "4  tensor([[[-0.3737,  0.4446,  0.3489,  ..., -0....   \n",
       "\n",
       "                         word_embedding_requirements  \\\n",
       "0  tensor([[[-0.2802,  0.0395,  0.0526,  ..., -0....   \n",
       "1  tensor([[[-0.2514, -0.0361,  0.2124,  ..., -0....   \n",
       "2  tensor([[[-0.2419, -0.0465,  0.6407,  ..., -0....   \n",
       "3  tensor([[[-0.2363,  0.1603,  0.1603,  ..., -0....   \n",
       "4  tensor([[[-0.4553,  0.0736,  0.1529,  ..., -0....   \n",
       "\n",
       "                             word_embedding_benefits  \n",
       "0  tensor([[[-0.4404,  0.1208, -0.3744,  ..., -0....  \n",
       "1  tensor([[[-0.2629,  0.1672,  0.4715,  ..., -0....  \n",
       "2  tensor([[[-0.4404,  0.1208, -0.3744,  ..., -0....  \n",
       "3  tensor([[[ 0.0051, -0.1624, -0.1307,  ..., -0....  \n",
       "4  tensor([[[-2.5761e-01,  3.7348e-02, -3.8978e-0...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyw/opt/anaconda3/envs/ada/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "bert_data = pd.read_pickle('tensor_bert_data.pkl')\n",
    "#bert_data = pd.read_csv(\"bert_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_data['word_embedding_title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_bert_data = pd.DataFrame()\n",
    "\n",
    "mean_embeddings = [torch.mean(embedding, dim=0) for embedding in bert_data['word_embedding_title']]\n",
    "resized_bert_data['word_embedding_title'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings = [torch.mean(embedding, dim=0) for embedding in bert_data['word_embedding_company_profile']]\n",
    "resized_bert_data['word_embedding_company_profile'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings = [torch.mean(embedding, dim=0) for embedding in bert_data['word_embedding_description']]\n",
    "resized_bert_data['word_embedding_description'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings = [torch.mean(embedding, dim=0) for embedding in bert_data['word_embedding_requirements']]\n",
    "resized_bert_data['word_embedding_requirements'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings = [torch.mean(embedding, dim=0) for embedding in bert_data['word_embedding_benefits']]\n",
    "resized_bert_data['word_embedding_benefits'] = mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_bert_data.to_csv(\"resized_bert_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(vect_df, y, test_size=0.2, random_state=42)\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(bert_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/2682760496.py:2: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  X_train_bert_concat = np.vstack([np.array(X_train_bert[col].tolist()) for col in X_train_bert.columns])\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/2682760496.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_bert_concat = np.vstack([np.array(X_train_bert[col].tolist()) for col in X_train_bert.columns])\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/2682760496.py:3: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  X_test_bert_concat = np.vstack([np.array(X_test_bert[col].tolist()) for col in X_test_bert.columns])\n",
      "/var/folders/yt/170z436920j8xfh51ybwr4hr0000gn/T/ipykernel_2800/2682760496.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_bert_concat = np.vstack([np.array(X_test_bert[col].tolist()) for col in X_test_bert.columns])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate BERT embeddings\n",
    "X_train_bert_concat = np.vstack([np.array(X_train_bert[col].tolist()) for col in X_train_bert.columns])\n",
    "X_test_bert_concat = np.vstack([np.array(X_test_bert[col].tolist()) for col in X_test_bert.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Logistic Regression model on training set is  [0.97833683 0.9650594  0.96645702 0.97134871 0.97412587 0.96993007\n",
      " 0.96923077 0.96643357 0.96993007 0.96993007]\n",
      "The f1 score of Logistic Regression model on training set is  [0.73043478 0.52830189 0.53846154 0.61682243 0.67826087 0.57425743\n",
      " 0.59259259 0.55555556 0.63865546 0.59047619]\n",
      "The average_precision score of Logistic Regression model on training set is  [0.86261683 0.68377194 0.72323117 0.7429452  0.83697549 0.75682005\n",
      " 0.79131151 0.6789852  0.71813048 0.76600983]\n",
      "The recall score of Logistic Regression model on training set is  [0.60869565 0.4057971  0.4057971  0.47826087 0.57352941 0.42647059\n",
      " 0.47058824 0.44117647 0.55882353 0.44927536]\n",
      "The roc_auc score of Logistic Regression model on training set is  [0.98746515 0.9675988  0.97752666 0.9587031  0.98896519 0.97370865\n",
      " 0.98055412 0.94456681 0.96977844 0.96513646]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "measure_metrics = ['accuracy', 'f1', 'average_precision', 'recall', 'roc_auc']\n",
    "for sco_name in measure_metrics:\n",
    "    score = cross_val_score(lr_tfidf, X_train_tfidf, y_train_tfidf, scoring=sco_name, cv=10)\n",
    "    print(\"The\", sco_name, \"score of Logistic Regression model on training set is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Logistic Regression model on test set is 0.9717561521252797\n",
      "The average precision score of Logistic Regression model on test set is 0.45748443499101665\n",
      "The recall score of Logistic Regression model on test set is 0.8636363636363636\n",
      "The f1 score of Logistic Regression model on test set is 0.6529209621993127\n",
      "The roc_auc score of Logistic Regression model on test set is 0.9194119498504958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score, roc_auc_score\n",
    "\n",
    "lr_tfidf_pre_accuracy = accuracy_score(lr_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "lr_tfidf_pre_average_precision = average_precision_score(lr_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "lr_tfidf_pre_recall = recall_score(lr_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "lr_tfidf_pre_f1 = f1_score(lr_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "lr_tfidf_pre_roc_auc = roc_auc_score(lr_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "\n",
    "print(\"The accuracy score of Logistic Regression model on test set is\", lr_tfidf_pre_accuracy)\n",
    "print(\"The average precision score of Logistic Regression model on test set is\", lr_tfidf_pre_average_precision)\n",
    "print(\"The recall score of Logistic Regression model on test set is\", lr_tfidf_pre_recall)\n",
    "print(\"The f1 score of Logistic Regression model on test set is\", lr_tfidf_pre_f1)\n",
    "print(\"The roc_auc score of Logistic Regression model on test set is\", lr_tfidf_pre_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Naive Bayes model on training set is  [0.9594689  0.94129979 0.95807128 0.94549266 0.94545455 0.95314685\n",
      " 0.95594406 0.94195804 0.95104895 0.95104895]\n",
      "The f1 score of Naive Bayes model on training set is  [0.5915493  0.4        0.55223881 0.42647059 0.44285714 0.464\n",
      " 0.53333333 0.45751634 0.5        0.453125  ]\n",
      "The average_precision score of Naive Bayes model on training set is  [0.69500647 0.47180853 0.61963895 0.44615176 0.5505796  0.53638567\n",
      " 0.60198423 0.51700996 0.55298859 0.52623393]\n",
      "The recall score of Naive Bayes model on training set is  [0.60869565 0.4057971  0.53623188 0.42028986 0.45588235 0.42647059\n",
      " 0.52941176 0.51470588 0.51470588 0.42028986]\n",
      "The roc_auc score of Naive Bayes model on training set is  [0.96108664 0.9252591  0.95103109 0.92036434 0.94831347 0.92778786\n",
      " 0.94504189 0.92708603 0.93012007 0.92182858]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "measure_metrics = ['accuracy', 'f1', 'average_precision', 'recall', 'roc_auc']\n",
    "for sco_name in measure_metrics:\n",
    "    score = cross_val_score(nb_tfidf, X_train_tfidf, y_train_tfidf, scoring=sco_name, cv=10)\n",
    "    print(\"The\", sco_name, \"score of Naive Bayes model on training set is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Naive Bayes model on test set is 0.9460290827740492\n",
      "The average precision score of Naive Bayes model on test set is 0.2525107979412443\n",
      "The recall score of Naive Bayes model on test set is 0.46774193548387094\n",
      "The f1 score of Naive Bayes model on test set is 0.4741144414168937\n",
      "The roc_auc score of Naive Bayes model on test set is 0.7200066609572747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score, roc_auc_score\n",
    "\n",
    "nb_tfidf_pre_accuracy = accuracy_score(nb_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "nb_tfidf_pre_average_precision = average_precision_score(nb_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "nb_tfidf_pre_recall = recall_score(nb_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "nb_tfidf_pre_f1 = f1_score(nb_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "nb_tfidf_pre_roc_auc = roc_auc_score(nb_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "\n",
    "print(\"The accuracy score of Naive Bayes model on test set is\", nb_tfidf_pre_accuracy)\n",
    "print(\"The average precision score of Naive Bayes model on test set is\", nb_tfidf_pre_average_precision)\n",
    "print(\"The recall score of Naive Bayes model on test set is\", nb_tfidf_pre_recall)\n",
    "print(\"The f1 score of Naive Bayes model on test set is\", nb_tfidf_pre_f1)\n",
    "print(\"The roc_auc score of Naive Bayes model on test set is\", nb_tfidf_pre_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_tfidf = RandomForestClassifier()\n",
    "rf_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Random Forest model on training set is  [0.97973445 0.98043326 0.97903564 0.97414396 0.98251748 0.97972028\n",
      " 0.97412587 0.97692308 0.97902098 0.97692308]\n",
      "The f1 score of Random Forest model on training set is  [0.77876106 0.75       0.68571429 0.65384615 0.76363636 0.72222222\n",
      " 0.68571429 0.69230769 0.71559633 0.7037037 ]\n",
      "The average_precision score of Random Forest model on training set is  [0.93241311 0.89103638 0.8958237  0.90489829 0.92941557 0.91869659\n",
      " 0.90678407 0.8097739  0.88808589 0.8991531 ]\n",
      "The recall score of Random Forest model on training set is  [0.57971014 0.60869565 0.57971014 0.49275362 0.63235294 0.61764706\n",
      " 0.52941176 0.52941176 0.57352941 0.55072464]\n",
      "The roc_auc score of Random Forest model on training set is  [0.99174807 0.98742259 0.99029028 0.99332291 0.99322471 0.99122722\n",
      " 0.99306275 0.97118209 0.99264706 0.99092739]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "measure_metrics = ['accuracy', 'f1', 'average_precision', 'recall', 'roc_auc']\n",
    "for sco_name in measure_metrics:\n",
    "    score = cross_val_score(rf_tfidf, X_train_tfidf, y_train_tfidf, scoring=sco_name, cv=10)\n",
    "    print(\"The\", sco_name, \"score of Random Forest model on training set is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Random Forest model on test set is 0.979586129753915\n",
      "The average precision score of Random Forest model on test set is 0.5970149509481706\n",
      "The recall score of Random Forest model on test set is 0.990909090909091\n",
      "The f1 score of Random Forest model on test set is 0.7491408934707904\n",
      "The roc_auc score of Random Forest model on test set is 0.9850679326443897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score, roc_auc_score\n",
    "\n",
    "rf_tfidf_pre_accuracy = accuracy_score(rf_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "rf_tfidf_pre_average_precision = average_precision_score(rf_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "rf_tfidf_pre_recall = recall_score(rf_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "rf_tfidf_pre_f1 = f1_score(rf_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "rf_tfidf_pre_roc_auc = roc_auc_score(rf_tfidf.predict(X_test_tfidf), y_test_tfidf)\n",
    "\n",
    "print(\"The accuracy score of Random Forest model on test set is\", rf_tfidf_pre_accuracy)\n",
    "print(\"The average precision score of Random Forest model on test set is\", rf_tfidf_pre_average_precision)\n",
    "print(\"The recall score of Random Forest model on test set is\", rf_tfidf_pre_recall)\n",
    "print(\"The f1 score of Random Forest model on test set is\", rf_tfidf_pre_f1)\n",
    "print(\"The roc_auc score of Random Forest model on test set is\", rf_tfidf_pre_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Neural Network for Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_concat.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_bert_concat, y_train_bert, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_concat)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_bert, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
